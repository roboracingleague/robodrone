{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from functools import partial\n",
    "import json\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import tag_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_func_from_saved_model(saved_model_dir):\n",
    "    saved_model_loaded = tf.saved_model.load(saved_model_dir, tags=[tag_constants.SERVING])\n",
    "    graph_func = saved_model_loaded.signatures[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "    # module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n",
    "    #graph_func = hub.Module(\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\")\n",
    "    #module_handle = saved_model_dir\n",
    "    #module_handle = \"/home/obee/github/robodrone/brain/setpoint_calculator/src/models/input/ssd_mobilenet_v2\"\n",
    "    #graph_func = hub.load(module_handle).signatures['default']\n",
    "    return graph_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MetaGraphDef associated with tags 'serve' could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`\navailable_tags: [set()]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3d89b31c317f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_func_from_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/obee/github/robodrone/brain/setpoint_calculator/src/models/input/ssd_mobilenet_v2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-a24256aa2ad6>\u001b[0m in \u001b[0;36mget_func_from_saved_model\u001b[0;34m(saved_model_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_func_from_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msaved_model_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERVING\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgraph_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignature_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_SERVING_SIGNATURE_DEF_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#graph_func = hub.Module(\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m   \"\"\"\n\u001b[0;32m--> 517\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    546\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_v1_in_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags)\u001b[0m\n\u001b[1;32m    237\u001b[0m   \u001b[0;34m\"\"\"Load a v1-style SavedModel as an object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EagerSavedModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, tags)\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;34m\"\"\"Creates an object from the MetaGraph identified by `tags`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_meta_graph_def_from_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mload_shared_name_suffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_load_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     functions = function_deserialization.load_function_def_library(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py\u001b[0m in \u001b[0;36mget_meta_graph_def_from_tags\u001b[0;34m(self, tags)\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     return super(_EagerSavedModelLoader, self).get_meta_graph_def_from_tags(\n\u001b[0;32m---> 83\u001b[0;31m         tags)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mget_meta_graph_def_from_tags\u001b[0;34m(self, tags)\u001b[0m\n\u001b[1;32m    325\u001b[0m           \u001b[0;34m\" could not be found in SavedModel. To inspect available tag-sets in\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m           \u001b[0;34m\" the SavedModel, please use the SavedModel CLI: `saved_model_cli`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m           \"\\navailable_tags: \" + str(available_tags))\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_graph_def_to_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MetaGraphDef associated with tags 'serve' could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`\navailable_tags: [set()]"
     ]
    }
   ],
   "source": [
    "graph_func = get_func_from_saved_model(\"/home/obee/github/robodrone/brain/setpoint_calculator/src/models/input/ssd_mobilenet_v2\")\n",
    "print(list(graph_func.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_func(input_saved_model_dir,\n",
    "                   data_dir,\n",
    "                   calib_data_dir,\n",
    "                   annotation_path,\n",
    "                   input_size,\n",
    "                   output_saved_model_dir=None,\n",
    "                   conversion_params=trt.DEFAULT_TRT_CONVERSION_PARAMS,\n",
    "                   use_trt=False,\n",
    "                   num_calib_inputs=None,\n",
    "                   use_synthetic=False,\n",
    "                   batch_size=None,\n",
    "                   optimize_offline=False):\n",
    "  \"\"\"Retreives a frozen SavedModel and applies TF-TRT\n",
    "  use_trt: bool, if true use TensorRT\n",
    "  precision: str, floating point precision (FP32, FP16, or INT8)\n",
    "  batch_size: int, batch size for TensorRT optimizations\n",
    "  returns: TF function that is ready to run for inference\n",
    "  \"\"\"\n",
    "  start_time = time.time()\n",
    "  graph_func = get_func_from_saved_model(input_saved_model_dir)\n",
    "  if use_trt:\n",
    "    converter = trt.TrtGraphConverterV2(\n",
    "        input_saved_model_dir=input_saved_model_dir,\n",
    "        conversion_params=conversion_params,\n",
    "    )\n",
    "    def input_fn(input_data_dir, num_iterations):\n",
    "      dataset, image_ids = get_dataset(\n",
    "          images_dir=input_data_dir,\n",
    "          annotation_path=annotation_path,\n",
    "          batch_size=batch_size,\n",
    "          use_synthetic=False,\n",
    "          input_size=input_size)\n",
    "      for i, batch_images in enumerate(dataset):\n",
    "        if i >= num_iterations:\n",
    "          break\n",
    "        yield (batch_images,)\n",
    "        print(\"  step %d/%d\" % (i+1, num_iterations))\n",
    "        i += 1\n",
    "    if conversion_params.precision_mode != 'INT8':\n",
    "      print('Graph conversion...')\n",
    "      converter.convert()\n",
    "      if optimize_offline:\n",
    "        print('Building TensorRT engines...')\n",
    "        converter.build(input_fn=partial(input_fn, data_dir, 1))\n",
    "      converter.save(output_saved_model_dir=output_saved_model_dir)\n",
    "      graph_func = get_func_from_saved_model(output_saved_model_dir)\n",
    "    else:\n",
    "      print('Graph conversion and INT8 calibration...')\n",
    "      converter.convert(calibration_input_fn=partial(\n",
    "          input_fn, calib_data_dir, num_calib_inputs//batch_size))\n",
    "      if optimize_offline:\n",
    "        print('Building TensorRT engines...')\n",
    "        converter.build(input_fn=partial(input_fn, data_dir, 1))\n",
    "      converter.save(output_saved_model_dir=output_saved_model_dir)\n",
    "      graph_func = get_func_from_saved_model(output_saved_model_dir)\n",
    "  return graph_func, {'conversion': time.time() - start_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(graph_func,\n",
    "                  data_dir,\n",
    "                  annotation_path,\n",
    "                  batch_size,\n",
    "                  input_size,\n",
    "                  num_iterations,\n",
    "                  num_warmup_iterations,\n",
    "                  use_synthetic,\n",
    "                  display_every=100,\n",
    "                  mode='validation',\n",
    "                  target_duration=None):\n",
    "  \"\"\"Run the given graph_func on the data files provided. In validation mode,\n",
    "  it consumes TFRecords with labels and reports accuracy. In benchmark mode, it\n",
    "  times inference on real data (.jpgs).\n",
    "  \"\"\"\n",
    "  results = {}\n",
    "  predictions = {}\n",
    "  iter_times = []\n",
    "  initial_time = time.time()\n",
    "\n",
    "  dataset, image_ids = get_dataset(images_dir=data_dir,\n",
    "                        annotation_path=annotation_path,\n",
    "                        batch_size=batch_size,\n",
    "                        use_synthetic=use_synthetic,\n",
    "                        input_size=input_size)\n",
    "  if mode == 'validation':\n",
    "    for i, batch_images in enumerate(dataset):\n",
    "      start_time = time.time()\n",
    "      batch_preds = graph_func(batch_images)\n",
    "      end_time = time.time()\n",
    "      iter_times.append(end_time - start_time)\n",
    "      for key in batch_preds.keys():\n",
    "        if key not in predictions:\n",
    "          predictions[key] = [batch_preds[key]]\n",
    "        else:\n",
    "          predictions[key].append(batch_preds[key])\n",
    "      if i % display_every == 0:\n",
    "        print(\"  step %d/%d, iter_time(ms)=%.0f\" %\n",
    "              (i+1, 4096//batch_size, iter_times[-1]*1000))\n",
    "      if i > 1 and target_duration is not None and \\\n",
    "        time.time() - initial_time > target_duration:\n",
    "        break\n",
    "  elif mode == 'benchmark':\n",
    "    for i, batch_images in enumerate(dataset):\n",
    "      if i >= num_warmup_iterations:\n",
    "        start_time = time.time()\n",
    "        batch_preds = list(graph_func(batch_images).values())[0].numpy()\n",
    "        iter_times.append(time.time() - start_time)\n",
    "        if i % display_every == 0:\n",
    "          print(\"  step %d/%d, iter_time(ms)=%.0f\" %\n",
    "                (i+1, num_iterations, iter_times[-1]*1000))\n",
    "      else:\n",
    "        batch_preds = list(graph_func(batch_images).values())[0].numpy()\n",
    "      if i > 0 and target_duration is not None and \\\n",
    "        time.time() - initial_time > target_duration:\n",
    "        break\n",
    "      if num_iterations is not None and i >= num_iterations:\n",
    "        break\n",
    "\n",
    "  if not iter_times:\n",
    "    return results\n",
    "  iter_times = np.array(iter_times)\n",
    "  iter_times = iter_times[num_warmup_iterations:]\n",
    "  results['total_time'] = np.sum(iter_times)\n",
    "  results['images_per_sec'] = np.mean(batch_size / iter_times)\n",
    "  results['99th_percentile'] = np.percentile(\n",
    "      iter_times, q=99, interpolation='lower') * 1000\n",
    "  results['latency_mean'] = np.mean(iter_times) * 1000\n",
    "  results['latency_median'] = np.median(iter_times) * 1000\n",
    "  results['latency_min'] = np.min(iter_times) * 1000\n",
    "  return results, predictions, image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(predictions, image_ids, annotation_path):\n",
    "  name_map = {\n",
    "      'output_0':'boxes',\n",
    "      'output_1':'classes',\n",
    "      'output_2':'num_detections',\n",
    "      'output_3':'scores',\n",
    "  }\n",
    "  for old_key in list(predictions.keys()):\n",
    "    if old_key in name_map:\n",
    "      new_key = name_map[old_key]\n",
    "      predictions[new_key] = predictions[old_key]\n",
    "      del predictions[old_key]\n",
    "  for key in predictions:\n",
    "    predictions[key] = [t.numpy() for t in predictions[key]]\n",
    "    predictions[key] = np.vstack(predictions[key])\n",
    "    if key == 'num_detections':\n",
    "      predictions[key] = predictions[key].ravel()\n",
    "    \n",
    "  coco = COCO(annotation_file=annotation_path)\n",
    "  coco_detections = []\n",
    "  for i, image_id in enumerate(image_ids):\n",
    "    coco_img = coco.imgs[image_id]\n",
    "    image_width = coco_img['width']\n",
    "    image_height = coco_img['height']\n",
    "\n",
    "    for j in range(int(predictions['num_detections'][i])):\n",
    "      bbox = predictions['boxes'][i][j]\n",
    "      y1, x1, y2, x2 = list(bbox)\n",
    "      bbox_coco_fmt = [\n",
    "        x1 * image_width,  # x0\n",
    "        y1 * image_height,  # x1\n",
    "        (x2 - x1) * image_width,  # width\n",
    "        (y2 - y1) * image_height,  # height\n",
    "      ]\n",
    "      coco_detection = {\n",
    "        'image_id': image_id,\n",
    "        'category_id': int(predictions['classes'][i][j]),\n",
    "        'bbox': [int(coord) for coord in bbox_coco_fmt],\n",
    "        'score': float(predictions['scores'][i][j])\n",
    "      }\n",
    "      coco_detections.append(coco_detection)\n",
    "  # write coco detections to file\n",
    "  tmp_dir = 'tmp_detection_results'\n",
    "  subprocess.call(['mkdir', '-p', tmp_dir])\n",
    "  coco_detections_path = os.path.join(tmp_dir, 'coco_detections.json')\n",
    "  with open(coco_detections_path, 'w') as f:\n",
    "    json.dump(coco_detections, f)\n",
    "  cocoDt = coco.loadRes(coco_detections_path)\n",
    "  subprocess.call(['rm', '-r', tmp_dir])\n",
    "\n",
    "  # compute coco metrics\n",
    "  eval = COCOeval(coco, cocoDt, 'bbox')\n",
    "  eval.params.imgIds = image_ids\n",
    "\n",
    "  eval.evaluate()\n",
    "  eval.accumulate()\n",
    "  eval.summarize()\n",
    "\n",
    "  return eval.stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_gpu_memory(gpu_mem_cap):\n",
    "  gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "  if not gpus:\n",
    "    return\n",
    "  print('Found the following GPUs:')\n",
    "  for gpu in gpus:\n",
    "    print('  ', gpu)\n",
    "  for gpu in gpus:\n",
    "    try:\n",
    "      if not gpu_mem_cap:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "      else:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpu,\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(\n",
    "                memory_limit=gpu_mem_cap)])\n",
    "    except RuntimeError as e:\n",
    "      print('Can not set GPU memory config', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trt_conversion_params(max_workspace_size_bytes,\n",
    "                              precision_mode,\n",
    "                              minimum_segment_size,\n",
    "                              max_batch_size):\n",
    "  conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "  conversion_params = conversion_params._replace(\n",
    "      max_workspace_size_bytes=max_workspace_size_bytes)\n",
    "  conversion_params = conversion_params._replace(precision_mode=precision_mode)\n",
    "  conversion_params = conversion_params._replace(\n",
    "      minimum_segment_size=minimum_segment_size)\n",
    "  conversion_params = conversion_params._replace(\n",
    "      use_calibration=precision_mode == 'INT8')\n",
    "  conversion_params = conversion_params._replace(\n",
    "      max_batch_size=max_batch_size)\n",
    "  return conversion_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  logging.getLogger(\"tensorflow\").setLevel(logging.INFO)\n",
    "\n",
    "  parser = argparse.ArgumentParser(description='Evaluate model')\n",
    "  parser.add_argument('--input_saved_model_dir', type=str, default=None,\n",
    "                      help='Directory containing the input saved model.')\n",
    "  parser.add_argument('--output_saved_model_dir', type=str, default=None,\n",
    "                      help='Directory in which the converted model is saved')\n",
    "  parser.add_argument('--input_size', type=int, default=640,\n",
    "                      help='Size of input images expected by the model')\n",
    "  parser.add_argument('--data_dir', type=str, default=None,\n",
    "                      help='Directory containing validation set'\n",
    "                      'TFRecord files.')\n",
    "  parser.add_argument('--annotation_path', type=str,\n",
    "                      help='Path that contains COCO annotations')\n",
    "  parser.add_argument('--calib_data_dir', type=str,\n",
    "                      help='Directory containing TFRecord files for'\n",
    "                      'calibrating INT8.')\n",
    "  parser.add_argument('--use_trt', action='store_true',\n",
    "                      help='If set, the graph will be converted to a'\n",
    "                      'TensorRT graph.')\n",
    "  parser.add_argument('--optimize_offline', action='store_true',\n",
    "                      help='If set, TensorRT engines are built'\n",
    "                      'before runtime.')\n",
    "  parser.add_argument('--precision', type=str,\n",
    "                      choices=['FP32', 'FP16', 'INT8'], default='FP32',\n",
    "                      help='Precision mode to use. FP16 and INT8 only'\n",
    "                      'work in conjunction with --use_trt')\n",
    "  parser.add_argument('--batch_size', type=int, default=8,\n",
    "                      help='Number of images per batch.')\n",
    "  parser.add_argument('--minimum_segment_size', type=int, default=2,\n",
    "                      help='Minimum number of TF ops in a TRT engine.')\n",
    "  parser.add_argument('--num_iterations', type=int, default=2048,\n",
    "                      help='How many iterations(batches) to evaluate.'\n",
    "                      'If not supplied, the whole set will be evaluated.')\n",
    "  parser.add_argument('--display_every', type=int, default=100,\n",
    "                      help='Number of iterations executed between'\n",
    "                      'two consecutive display of metrics')\n",
    "  parser.add_argument('--use_synthetic', action='store_true',\n",
    "                      help='If set, one batch of random data is'\n",
    "                      'generated and used at every iteration.')\n",
    "  parser.add_argument('--num_warmup_iterations', type=int, default=50,\n",
    "                      help='Number of initial iterations skipped from timing')\n",
    "  parser.add_argument('--num_calib_inputs', type=int, default=500,\n",
    "                      help='Number of inputs (e.g. images) used for'\n",
    "                      'calibration (last batch is skipped in case'\n",
    "                      'it is not full)')\n",
    "  parser.add_argument('--gpu_mem_cap', type=int, default=0,\n",
    "                      help='Upper bound for GPU memory in MB.'\n",
    "                      'Default is 0 which means allow_growth will be used')\n",
    "  parser.add_argument('--max_workspace_size', type=int, default=(1<<30),\n",
    "                      help='workspace size in bytes')\n",
    "  parser.add_argument('--mode', choices=['validation', 'benchmark'],\n",
    "                      default='validation',\n",
    "                      help='Which mode to use (validation or benchmark)')\n",
    "  parser.add_argument('--target_duration', type=int, default=None,\n",
    "                      help='If set, script will run for specified'\n",
    "                      'number of seconds.')\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  if args.precision != 'FP32' and not args.use_trt:\n",
    "    raise ValueError('TensorRT must be enabled for FP16'\n",
    "                     'or INT8 modes (--use_trt).')\n",
    "  if (args.precision == 'INT8' and not args.calib_data_dir\n",
    "      and not args.use_synthetic):\n",
    "    raise ValueError('--calib_data_dir is required for INT8 mode')\n",
    "  if (args.num_iterations is not None\n",
    "      and args.num_iterations <= args.num_warmup_iterations):\n",
    "    raise ValueError(\n",
    "        '--num_iterations must be larger than --num_warmup_iterations '\n",
    "        '({} <= {})'.format(args.num_iterations, args.num_warmup_iterations))\n",
    "  if args.num_calib_inputs < args.batch_size:\n",
    "    raise ValueError(\n",
    "        '--num_calib_inputs must not be smaller than --batch_size'\n",
    "        '({} <= {})'.format(args.num_calib_inputs, args.batch_size))\n",
    "  if args.mode == 'validation' and args.use_synthetic:\n",
    "    raise ValueError('Cannot use both validation mode and synthetic dataset')\n",
    "  if args.data_dir is None and not args.use_synthetic:\n",
    "    raise ValueError(\"--data_dir required if you are not using synthetic data\")\n",
    "  if args.use_synthetic and args.num_iterations is None:\n",
    "    raise ValueError(\"--num_iterations is required for --use_synthetic\")\n",
    "  if args.use_trt and not args.output_saved_model_dir:\n",
    "    raise ValueError(\"--output_saved_model_dir must be set if use_trt=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_gpu_mem_cap = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following GPUs:\n",
      "   PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "config_gpu_memory(args_gpu_mem_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_max_workspace_size = (1 << 31) \n",
    "args_precision = 'FP16'\n",
    "args_minimum_segment_size = 1\n",
    "args_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_trt_conversion_params(\n",
    "      args_max_workspace_size,\n",
    "      args_precision,\n",
    "      args_minimum_segment_size,\n",
    "      args_batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_input_saved_model_dir = \"/home/obee/github/robodrone/brain/setpoint_calculator/src/models/input/ssd_mobilenet_v2\"\n",
    "args_output_saved_model_dir = \"home/obee/github/robodrone/brain/setpoint_calculator/src/models/output/ssd_mobilenet_v2_coco_2018_03_29/trt\"\n",
    "args_data_dir = \"\"\n",
    "args_calib_data_dir = \"\"\n",
    "args_annotation_path = \"\"\n",
    "args_input_size = 300\n",
    "args_use_trt = True\n",
    "args_batch_size = 1\n",
    "args_num_calib_inputs = None\n",
    "args_use_synthetic = False\n",
    "args_optimize_offline = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MetaGraphDef associated with tags 'serve' could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`\navailable_tags: [set()]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7f6f78b63b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mnum_calib_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs_num_calib_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0muse_synthetic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs_use_synthetic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       optimize_offline=args_optimize_offline)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-87b17df244c9>\u001b[0m in \u001b[0;36mget_graph_func\u001b[0;34m(input_saved_model_dir, data_dir, calib_data_dir, annotation_path, input_size, output_saved_model_dir, conversion_params, use_trt, num_calib_inputs, use_synthetic, batch_size, optimize_offline)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \"\"\"\n\u001b[1;32m     19\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mgraph_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_func_from_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_saved_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_trt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     converter = trt.TrtGraphConverterV2(\n",
      "\u001b[0;32m<ipython-input-2-a24256aa2ad6>\u001b[0m in \u001b[0;36mget_func_from_saved_model\u001b[0;34m(saved_model_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_func_from_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msaved_model_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERVING\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgraph_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignature_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_SERVING_SIGNATURE_DEF_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#graph_func = hub.Module(\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m   \"\"\"\n\u001b[0;32m--> 517\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    546\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_v1_in_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags)\u001b[0m\n\u001b[1;32m    237\u001b[0m   \u001b[0;34m\"\"\"Load a v1-style SavedModel as an object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EagerSavedModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, tags)\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;34m\"\"\"Creates an object from the MetaGraph identified by `tags`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_meta_graph_def_from_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mload_shared_name_suffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_load_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     functions = function_deserialization.load_function_def_library(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load_v1_in_v2.py\u001b[0m in \u001b[0;36mget_meta_graph_def_from_tags\u001b[0;34m(self, tags)\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     return super(_EagerSavedModelLoader, self).get_meta_graph_def_from_tags(\n\u001b[0;32m---> 83\u001b[0;31m         tags)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mload_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mget_meta_graph_def_from_tags\u001b[0;34m(self, tags)\u001b[0m\n\u001b[1;32m    325\u001b[0m           \u001b[0;34m\" could not be found in SavedModel. To inspect available tag-sets in\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m           \u001b[0;34m\" the SavedModel, please use the SavedModel CLI: `saved_model_cli`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m           \"\\navailable_tags: \" + str(available_tags))\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmeta_graph_def_to_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MetaGraphDef associated with tags 'serve' could not be found in SavedModel. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`\navailable_tags: [set()]"
     ]
    }
   ],
   "source": [
    "graph_func, times = get_graph_func(\n",
    "      input_saved_model_dir=args_input_saved_model_dir,\n",
    "      output_saved_model_dir=args_output_saved_model_dir,\n",
    "      data_dir=args_data_dir,\n",
    "      calib_data_dir=args_calib_data_dir,\n",
    "      annotation_path=args_annotation_path,\n",
    "      input_size=args_input_size,\n",
    "      conversion_params=params,\n",
    "      use_trt=args_use_trt,\n",
    "      batch_size=args_batch_size,\n",
    "      num_calib_inputs=args_num_calib_inputs,\n",
    "      use_synthetic=args_use_synthetic,\n",
    "      optimize_offline=args_optimize_offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dict(input_dict, prefix='  ', postfix=''):\n",
    "    for k, v in sorted(input_dict.items()):\n",
    "      print('{}{}: {}{}'.format(prefix, k, '%.1f'%v if isinstance(v, float) else v, postfix))\n",
    "  print('Benchmark arguments:')\n",
    "  print_dict(vars(args))\n",
    "  print('TensorRT Conversion Params:')\n",
    "  print_dict(dict(params._asdict()))\n",
    "  print('Conversion times:')\n",
    "  print_dict(times, postfix='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, predictions, image_ids = run_inference(graph_func,\n",
    "                data_dir=args.data_dir,\n",
    "                annotation_path=args.annotation_path,\n",
    "                batch_size=args.batch_size,\n",
    "                num_iterations=args.num_iterations,\n",
    "                num_warmup_iterations=args.num_warmup_iterations,\n",
    "                input_size=args.input_size,\n",
    "                use_synthetic=args.use_synthetic,\n",
    "                display_every=args.display_every,\n",
    "                mode=args.mode,\n",
    "                target_duration=args.target_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Results:')\n",
    "  if args.mode == 'validation':\n",
    "    mAP = eval_model(predictions, image_ids, args.annotation_path)\n",
    "    print('  mAP: %f' % mAP)\n",
    "  print('  images/sec: %d' % results['images_per_sec'])\n",
    "  print('  99th_percentile(ms): %.2f' % results['99th_percentile'])\n",
    "  print('  total_time(s): %.1f' % results['total_time'])\n",
    "  print('  latency_mean(ms): %.2f' % results['latency_mean'])\n",
    "  print('  latency_median(ms): %.2f' % results['latency_median'])\n",
    "  print('  latency_min(ms): %.2f' % results['latency_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "conversion_params = conversion_params._replace(max_workspace_size_bytes=(1<<32))\n",
    "conversion_params = conversion_params._replace(precision_mode=\"FP16\")\n",
    "conversion_params = conversion_params._replace(maximum_cached_engines=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_saved_model_dir = \"/home/obee/github/robodrone/brain/setpoint_calculator/src/models/input/ssd_mobilenet_v2\"\n",
    "output_saved_model_tmp_dir = \"/home/obee/github/robodrone/brain/setpoint_calculator/src/models/output/tmp/3\"\n",
    "output_saved_model_dir = \"home/obee/github/robodrone/brain/setpoint_calculator/src/models/output/ssd_mobilenet_v2_coco_2018_03_29/trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a90f6df15c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaved_model_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_saved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERVING\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtmp_full_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignature_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_SERVING_SIGNATURE_DEF_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m   \"\"\"\n\u001b[0;32m--> 517\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;31m# sequences for nest.flatten, so we put those through as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m   \u001b[0msaved_model_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1\n\u001b[1;32m    528\u001b[0m       and saved_model_proto.meta_graphs[0].HasField(\"object_graph_def\")):\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_pb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m       \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/message.py\u001b[0m in \u001b[0;36mParseFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \"\"\"\n\u001b[1;32m    186\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mMergeFromString\u001b[0;34m(self, serialized)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m         \u001b[0;31m# The only reason _InternalParse would return early is if it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;31m# encountered an end-group tag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mInternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\u001b[0m in \u001b[0;36mDecodeRepeatedField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    715\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0m_DecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Truncated message.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;31m# Read sub-message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m           \u001b[0;31m# The only reason _InternalParse would return early is if it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m           \u001b[0;31m# encountered an end-group tag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mInternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\u001b[0m in \u001b[0;36mDecodeField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0m_DecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Truncated message.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m       \u001b[0;31m# Read sub-message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         \u001b[0;31m# The only reason _InternalParse would return early is if it encountered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;31m# an end-group tag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mInternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\u001b[0m in \u001b[0;36mDecodeRepeatedField\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    715\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0m_DecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Truncated message.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;31m# Read sub-message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalParse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m           \u001b[0;31m# The only reason _InternalParse would return early is if it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m           \u001b[0;31m# encountered an end-group tag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mInternalParse\u001b[0;34m(self, buffer, pos, end)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfield_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UpdateOneofState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py\u001b[0m in \u001b[0;36mDecodeMap\u001b[0;34m(buffer, pos, end, message, field_dict)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_message_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/message.py\u001b[0m in \u001b[0;36mCopyFrom\u001b[0;34m(self, other_msg)\u001b[0m\n\u001b[1;32m    116\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mClear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mMergeFrom\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m   1324\u001b[0m             \u001b[0mfield_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m             \u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1326\u001b[0;31m           \u001b[0mfield_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mMergeFrom\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m   1316\u001b[0m           \u001b[0mfield_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m           \u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m         \u001b[0mfield_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpp_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCPPTYPE_MESSAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_present_in_parent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/containers.py\u001b[0m in \u001b[0;36mMergeFrom\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0mone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopying\u001b[0m \u001b[0meach\u001b[0m \u001b[0mindividual\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \"\"\"\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/containers.py\u001b[0m in \u001b[0;36mextend\u001b[0;34m(self, elem_seq)\u001b[0m\n\u001b[1;32m    411\u001b[0m       \u001b[0mnew_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m       \u001b[0mnew_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SetListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m       \u001b[0mnew_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m       \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mlistener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModified\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36mMergeFrom\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m   1316\u001b[0m           \u001b[0mfield_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m           \u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m         \u001b[0mfield_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpp_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCPPTYPE_MESSAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_present_in_parent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/containers.py\u001b[0m in \u001b[0;36mMergeFrom\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0mone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopying\u001b[0m \u001b[0meach\u001b[0m \u001b[0mindividual\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \"\"\"\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/containers.py\u001b[0m in \u001b[0;36mextend\u001b[0;34m(self, elem_seq)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m       \u001b[0mnew_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m       \u001b[0mnew_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SetListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0mnew_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_present_in_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_listener_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNullMessageListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listener_for_children\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Listener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m       \u001b[0mfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_GetFieldByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent_message)\u001b[0m\n\u001b[1;32m   1489\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_message_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_message_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m     \u001b[0;31m# As an optimization, we also indicate directly on the listener whether\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saved_model_loaded = tf.saved_model.load(input_saved_model_dir, tags=[tag_constants.SERVING])\n",
    "tmp_full_model = saved_model_loaded.signatures[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "saved_model_loaded = tf.saved_model.load(input_saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SignatureMap({'default': <tensorflow.python.eager.wrap_function.WrappedFunction object at 0x7f15666c88>})\n"
     ]
    }
   ],
   "source": [
    "print(saved_model_loaded.signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.training.tracking.tracking.AutoTrackable'>\n"
     ]
    }
   ],
   "source": [
    "print(type(saved_model_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/obee/github/robodrone/brain/setpoint_calculator/src/models/output/tmp/3/assets\n"
     ]
    }
   ],
   "source": [
    "# tf.saved_model.save(saved_model_loaded,output_saved_model_tmp_dir)\n",
    "tf.saved_model.save(saved_model_loaded,output_saved_model_tmp_dir, saved_model_loaded.signatures['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-08 22:57:35.581486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['images'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, -1, -1, 3)\n",
      "      name: serving_default_images:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['detection_boxes'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 4)\n",
      "      name: StatefulPartitionedCall_1:0\n",
      "  outputs['detection_class_entities'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall_1:1\n",
      "  outputs['detection_class_labels'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall_1:2\n",
      "  outputs['detection_class_names'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall_1:3\n",
      "  outputs['detection_scores'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall_1:4\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir /home/obee/github/robodrone/brain/setpoint_calculator/src/models/output/tmp/2 --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded = tf.saved_model.load(\"/home/obee/github/robodrone/brain/setpoint_calculator/src/models/output/tmp/2\")\n",
    "print(list(loaded.signatures.keys()))  # [\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f4aeca4cf954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loaded' is not defined"
     ]
    }
   ],
   "source": [
    "print(list(loaded.signatures.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (5, 1, 6)\n",
      "INFO:tensorflow:Loaded TensorRT version: (5, 1, 6)\n",
      "INFO:tensorflow:Running against TensorRT version 5.1.6\n"
     ]
    }
   ],
   "source": [
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir = output_saved_model_tmp_dir,\n",
    "    conversion_params=conversion_params)\n",
    "\n",
    "# saved_model_loaded = tf.saved_model.load(saved_model_dir, tags=[tag_constants.SERVING])\n",
    "#    graph_func = saved_model_loaded.signatures[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serving_default\n"
     ]
    }
   ],
   "source": [
    "print(signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-06 22:42:30.182106: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/saved_model_cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/saved_model_cli.py\", line 909, in main\n",
      "    args.func(args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/saved_model_cli.py\", line 621, in show\n",
      "    _show_inputs_outputs(args.dir, args.tag_set, args.signature_def)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/saved_model_cli.py\", line 133, in _show_inputs_outputs\n",
      "    tag_set)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/saved_model_utils.py\", line 113, in get_meta_graph_def\n",
      "    saved_model = read_saved_model(saved_model_dir)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/saved_model_utils.py\", line 55, in read_saved_model\n",
      "    raise IOError(\"SavedModel file does not exist at: %s\" % saved_model_dir)\n",
      "OSError: SavedModel file does not exist at: input_saved_model_dir\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir input_saved_model_dir --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.tar.gz  assets  SavedModel  saved_model.pb  tfhub_module.pb  variables\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/obee/github/robodrone/brain/setpoint_calculator/src/models/input/ssd_mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /home/obee/github/robodrone/brain/setpoint_calculator/src/models/input/ssd_mobilenet_v2/SavedModel.pb /home/obee/github/robodrone/brain/setpoint_calculator/src/models/input/ssd_mobilenet_v2/SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.build(input_fn=lambda : np.random.normal(\n",
    "        size=(8, 16, 16, 3)).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.save(output_saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_loaded = tf.saved_model.load(\n",
    "    output_saved_model_dir, tags=[tag_constants.SERVING])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_func = saved_model_loaded.signatures[\n",
    "    signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_func = convert_to_constants.convert_variables_to_constants_v2(\n",
    "    graph_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = frozen_func(input_data)[0].numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
